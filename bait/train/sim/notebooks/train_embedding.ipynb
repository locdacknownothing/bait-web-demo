{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[300]\n",
       "    resize_size=[320]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights = models.MobileNet_V3_Large_Weights.IMAGENET1K_V2\n",
    "weights = models.EfficientNet_B3_Weights.IMAGENET1K_V1\n",
    "# model = models.mobilenet_v3_large(weights)\n",
    "transform = weights.transforms()\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Assuming you have a dataset class that returns images as PIL Images\n",
    "def compute_mean_std(dataset):\n",
    "    loader = DataLoader(dataset, batch_size=1024, shuffle=False)\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    nb_samples = 0\n",
    "\n",
    "    for data in loader:\n",
    "        image = data\n",
    "        batch_samples = image.size(0)\n",
    "        image = image.view(batch_samples, image.size(1), -1)\n",
    "        mean += image.mean(2).sum(0)\n",
    "        std += image.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape = (224, 224)\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Resize(target_shape)]\n",
    ")\n",
    "\n",
    "train = torchvision.datasets.ImageFolder(\n",
    "    \"/mnt/data1/src/datasets/poi_train_val/train\",\n",
    "    transform=transform,\n",
    ")\n",
    "val = torchvision.datasets.ImageFolder(\n",
    "    \"/mnt/data1/src/datasets/poi_train_val/val\",\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class CustomData(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.data_img = np.array(self.data.imgs)[:, 0]\n",
    "        self.transform = self.data.transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data_img[index]\n",
    "        # print(img)\n",
    "        img = Image.open(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img.to(\"cuda:0\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "train_dataset = CustomData(train)\n",
    "val_dataset = CustomData(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.4062, 0.3848, 0.3771], device='cuda:0'), tensor([0.1590, 0.1555, 0.1497], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# print(compute_mean_std(train_dataset))\n",
    "print(compute_mean_std(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.randn(1,3,250,320)\n",
    "output = transforms(dummy_input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 300, 300])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms = models.EfficientNet_B3_Weights.IMAGENET1K_V1.transforms()\n",
    "output = transforms(dummy_input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    hàm loss triplet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.loss = nn.TripletMarginLoss(margin=margin, p=2, eps=1e-7)\n",
    "\n",
    "    def forward(self, anchor, positive, negative, size_average=True):\n",
    "        distance_positive = (anchor - positive).pow(2).sum(1)  # .pow(.5)\n",
    "        distance_negative = (anchor - negative).pow(2).sum(1)  # .pow(.5)\n",
    "        # distance_negative1 = (anchor - negative1).pow(2).sum(1)\n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        # losses = F.relu(distance_positive*2 - distance_negative - distance_negative1  + self.margin)\n",
    "        # return self.loss(anchor, positive, negative)\n",
    "        return losses.mean() if size_average else losses.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.convnet = nn.Sequential(*list(backbone.children())[:-1])\n",
    "        self.fc = nn.Sequential(nn.Linear(960, 512, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        flatten = self.convnet(x).flatten(start_dim=1)\n",
    "        backbone = flatten.view(flatten.size()[0], -1)\n",
    "        output = self.fc(backbone)\n",
    "        # return torch.cat((output, output1),1)\n",
    "        return output\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "        # self.convnet = nn.Sequential(nn.Conv2d(1, 32, 5), nn.PReLU(),\n",
    "        #                              nn.MaxPool2d(2, stride=2),\n",
    "        #                              nn.Conv2d(32, 64, 5), nn.PReLU(),\n",
    "        #                              nn.MaxPool2d(2, stride=2))\n",
    "\n",
    "        # self.fc1 = nn.Sequential(nn.Linear(960, 512),\n",
    "        #     nn.PReLU(),\n",
    "        #     nn.Linear(512, 256),\n",
    "        #     nn.PReLU(),\n",
    "        #     nn.Linear(256, 256)\n",
    "        # )\n",
    "        # self.fc2 = nn.Sequential(nn.Linear(960, 512),\n",
    "        #     nn.PReLU(),\n",
    "        #     nn.Linear(512, 256),\n",
    "        #     nn.PReLU(),\n",
    "        #     nn.Linear(256, 128)\n",
    "        # )\n",
    "\n",
    "\n",
    "class EmbeddingNetL2(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(EmbeddingNetL2, self).__init__()\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        flatten = self.backbone(x).flatten(start_dim=1)\n",
    "        output = flatten.view(flatten.size()[0], -1)\n",
    "        return F.normalize(output, p=2, dim=1)\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "\n",
    "# class ClassificationNet(nn.Module):\n",
    "#     def __init__(self, embedding_net, n_classes):\n",
    "#         super(ClassificationNet, self).__init__()\n",
    "#         self.embedding_net = embedding_net\n",
    "#         self.n_classes = n_classes\n",
    "#         self.nonlinear = nn.PReLU()\n",
    "#         self.fc1 = nn.Linear(256, n_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         output = self.embedding_net(x)\n",
    "#         output = self.nonlinear(output)\n",
    "#         scores = F.log_softmax(self.fc1(output), dim=-1)\n",
    "#         return scores\n",
    "\n",
    "#     def get_embedding(self, x):\n",
    "#         return self.nonlinear(self.embedding_net(x))\n",
    "\n",
    "\n",
    "# class SiameseNet(nn.Module):\n",
    "#     def __init__(self, embedding_net):\n",
    "#         super(SiameseNet, self).__init__()\n",
    "#         self.embedding_net = embedding_net\n",
    "\n",
    "#     def forward(self, x1, x2):\n",
    "#         output1 = self.embedding_net(x1)\n",
    "#         output2 = self.embedding_net(x2)\n",
    "#         return output1, output2\n",
    "\n",
    "#     def get_embedding(self, x):\n",
    "#         return self.embedding_net(x)\n",
    "\n",
    "\n",
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embedding_net = embedding_net\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "        output1 = self.embedding_net(x1)\n",
    "        output2 = self.embedding_net(x2)\n",
    "        output3 = self.embedding_net(x3)\n",
    "        return output1, output2, output3\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.embedding_net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4592,  0.1400,  0.2700,  0.3473,  0.2941,  0.3369,  0.2400,  0.6330,\n",
       "          0.3150,  0.4918,  0.2821,  0.2722,  0.1673,  0.3079,  0.7789,  0.1255,\n",
       "          0.6041,  0.5709,  0.3501,  0.1664,  0.4615, -0.0825,  0.0566,  0.0689,\n",
       "          0.5728,  0.2297,  0.2307,  0.1335,  0.2944,  0.2294,  0.3163,  0.4695,\n",
       "          0.2363,  0.5743,  0.1219,  0.7875,  0.2053,  0.8206,  0.4734,  0.2734,\n",
       "          0.2569,  0.3831,  0.2630,  0.2485,  0.1520,  0.2979,  0.2500,  0.2821,\n",
       "          0.2143,  0.3213,  0.5778,  0.1793,  0.2454,  0.2402,  0.1385,  0.7129,\n",
       "          0.5530,  0.5870,  0.5988,  0.3596,  0.4834,  0.3683,  0.1771,  0.4484,\n",
       "          0.3485,  0.6261,  0.3297,  0.2144,  0.4923,  0.2773,  0.2352,  0.1465,\n",
       "          0.5692,  0.8796,  0.1899,  0.1951,  0.6825,  0.0633,  0.4699,  0.2502,\n",
       "          0.1978,  0.8112,  0.6643,  0.3157,  0.3452,  0.1965,  0.1365,  0.3001,\n",
       "          0.3408,  0.0311,  0.3252,  0.9214,  0.4788,  0.2815,  0.7000,  0.3488,\n",
       "          0.3742,  0.1751,  0.2662,  0.3856,  0.2966,  0.3937,  0.3092,  0.2651,\n",
       "          0.3520,  0.4201,  0.2626,  0.2699,  0.1791,  0.5414,  0.4324,  0.1689,\n",
       "          0.1357,  0.2563,  0.3440,  0.3473,  0.2944,  0.7937,  0.1501,  0.1935,\n",
       "          0.1602,  0.3396,  0.1202,  0.4306,  0.5294,  0.8004,  0.5276,  0.1895,\n",
       "          0.3434,  0.3358,  0.3403,  0.5437,  0.3766,  0.7887,  0.4230,  0.3613,\n",
       "          0.7844,  0.2685,  0.3322,  0.6584,  0.2530,  0.2934,  0.4235,  0.2852,\n",
       "          0.3070,  0.4273,  0.3437,  0.5208,  0.2019,  0.1869,  0.6474,  0.5212,\n",
       "          0.4352,  0.2855,  0.5487,  0.4794,  0.6173,  0.1508,  0.2636,  0.3579,\n",
       "          0.2961,  0.0313,  0.0016,  0.6551,  0.4094,  0.2793,  0.2449,  0.2533,\n",
       "          0.3017,  0.3577,  0.3452,  0.2756,  0.2629,  0.0763,  0.1823,  0.5703,\n",
       "          0.2007,  0.3712,  0.2957,  0.3416,  0.3236,  0.1707,  0.6058,  0.1930,\n",
       "          0.3984,  0.3106,  0.3238,  0.2694,  0.2541,  0.4635,  0.6727,  0.4927,\n",
       "          0.7794,  0.2297,  0.5098,  0.5687,  0.1762,  0.5894,  0.3558,  0.2546,\n",
       "          0.3567,  0.1598,  0.2211,  0.2888,  0.4258,  0.2099,  0.2833,  0.3593,\n",
       "          0.3455,  0.3142,  0.6575,  0.3047,  0.3448,  0.4274,  0.2591,  0.3485,\n",
       "          0.1402,  0.2099,  0.3896,  0.3083,  0.6795,  0.2650,  0.3126,  0.5299,\n",
       "          0.1922,  0.2920,  0.2591,  0.6075,  0.6388,  0.2741,  0.2938,  0.2890,\n",
       "          0.1528,  0.6226,  0.1481,  0.4007,  0.0561,  0.1798,  0.4429,  0.3757,\n",
       "          0.6281,  0.6224,  0.3436,  0.2566,  0.0713,  0.8489,  0.2078,  0.2950,\n",
       "          0.8293,  0.2601,  0.2759,  0.2319,  0.3391,  0.5789,  0.2904,  0.2107,\n",
       "          0.2028,  0.3271,  0.7333,  0.2997,  0.5292,  0.6394,  0.4045,  0.3469,\n",
       "          0.2602,  0.6799,  0.2585,  0.1793,  0.1748,  0.5633,  0.2291,  0.3592,\n",
       "          0.2661,  0.4167,  0.2580,  0.2626,  0.6127,  0.2808,  0.3441,  0.2185,\n",
       "          0.1840,  0.1552,  0.3668,  0.1217,  0.6794,  0.1793,  0.5743,  0.3141,\n",
       "          0.2485,  0.3739,  0.5286,  0.6512,  0.2736,  0.2863,  0.1276,  0.3815,\n",
       "          0.1663,  0.3198,  0.5883,  0.8296,  0.0747,  0.2070,  0.1029,  0.1516,\n",
       "          0.9330,  0.5587,  0.1185,  0.3330,  0.3936,  0.3043,  0.1703,  0.4052,\n",
       "          0.4389,  0.3330,  0.5912,  0.2393,  0.3716,  0.1660,  0.2995,  0.5545,\n",
       "          0.2624,  0.4323,  0.3505,  0.0919,  0.6417,  0.4087,  0.4356,  0.2566,\n",
       "          0.3532,  0.8006,  0.2838,  0.2049,  0.7419,  0.4728,  0.8504,  0.3283,\n",
       "          0.4265,  0.1551,  0.5350,  0.2373,  0.2847,  0.5035,  0.7934,  0.5715,\n",
       "          0.2565,  0.4056,  0.2879,  0.4053,  0.0579,  0.3209,  0.3755,  0.3410,\n",
       "          0.5034,  0.1745,  0.1929,  0.5738,  0.2823,  0.3243,  0.1979,  0.1769,\n",
       "          0.6323,  0.1850,  0.5616,  0.1601,  0.4141,  0.1951,  0.3116,  0.0226,\n",
       "          0.2562,  0.1693,  0.5872,  0.3587,  0.3215,  0.3174,  0.2846,  0.6778,\n",
       "          0.7588,  0.6494,  0.3425,  0.2657,  0.3613,  0.6299,  0.1018,  0.2527,\n",
       "          0.2238,  0.8010,  0.3051,  0.3189,  0.4122,  0.1583,  0.2514,  0.2729,\n",
       "          0.2482,  0.2755,  0.2021,  0.7093,  0.5888,  0.1106,  0.3051,  0.3123,\n",
       "          0.6608,  0.1598,  0.2414,  0.3090,  0.6756,  0.6066,  0.3884,  0.4832,\n",
       "          0.1116,  0.4111,  0.5423,  0.5235,  0.7712,  0.3427,  0.6084,  0.1358,\n",
       "          0.3050,  0.0809,  0.2356,  0.2954,  0.4635,  0.2730,  0.2201,  0.7546,\n",
       "          0.1120,  0.2462,  0.0751,  0.3231,  0.2863,  0.1959,  0.2419,  0.2704,\n",
       "          0.2130,  0.2681,  0.1997,  0.3041,  0.4199,  0.0594,  0.7331,  0.1510,\n",
       "          0.2804,  0.1921,  0.6823,  0.1501,  0.3017,  0.4202,  0.4297,  0.3582,\n",
       "          0.2978,  0.3940,  0.0594,  0.5307,  0.0817,  0.4560,  0.5002,  0.4341,\n",
       "          0.1094,  0.1101,  0.3964,  0.1812,  0.5207,  0.3231,  0.3054,  0.7136,\n",
       "          0.4883,  0.2171,  0.4048,  0.5555,  0.2827,  0.2988,  0.2064,  0.2857,\n",
       "          0.1845,  0.3180,  0.3868,  0.3787,  0.6140,  0.1878,  0.7038,  0.3540,\n",
       "          0.2007,  0.2129,  0.4163,  0.3765,  0.2598,  0.3576,  0.0672,  0.1704,\n",
       "          0.3334,  0.2476, -0.0322,  0.2144,  0.2187,  0.0827,  0.3481,  0.1663,\n",
       "          0.5255,  0.0150,  0.3840,  0.6411,  0.4663,  0.2438,  0.1509,  0.8574,\n",
       "          0.2004,  0.1333,  0.1526,  0.1011,  0.3851,  0.3182,  0.6186,  0.2761,\n",
       "          0.0822,  0.2773,  0.3125,  0.5598,  0.2878,  0.2232,  0.5721,  0.1482,\n",
       "          0.2804,  0.4321,  0.3704,  0.6757,  0.4154,  0.5137,  0.1743,  0.6130,\n",
       "          0.2525,  0.4384,  0.2904,  0.2001,  0.3464,  0.2683,  0.7139,  0.6950,\n",
       "          0.6087,  0.2669,  0.2637,  0.1598,  0.3541,  0.3530,  0.1329,  0.6932,\n",
       "          0.1935,  0.3907,  0.1707,  0.1890,  0.6337,  0.3193,  0.5701,  0.3107,\n",
       "          0.2181,  0.2478,  0.1500,  0.2720,  0.7612,  0.2082,  0.2814,  0.2579,\n",
       "          0.7669,  0.2801,  0.2798,  0.2807,  0.3433,  0.1714,  0.3847,  0.3812,\n",
       "          0.1606,  0.4010,  0.3639,  0.1753,  0.1438,  0.1857,  0.5189,  0.3034,\n",
       "          0.5256,  0.1360,  0.6083,  0.5596,  0.2961,  0.4686,  0.3094,  0.3909,\n",
       "          0.3112,  0.6499,  0.2908,  0.6044,  0.0688,  0.2489,  0.1144,  0.2799,\n",
       "          0.2930,  0.3736,  0.6006,  0.1781,  0.2173,  0.4758,  0.8422,  0.1947,\n",
       "          0.0601,  0.2347,  0.4486,  0.3972,  0.2182,  0.3512,  0.3876,  0.5853,\n",
       "          0.5431,  0.3141,  0.4752,  0.2360,  0.2890,  0.1562,  0.3111,  0.2433,\n",
       "          0.3829,  0.1595,  0.1601,  0.1704,  0.3399,  0.3904,  0.4543,  0.5042,\n",
       "          0.1854,  0.4009,  0.3600,  0.7979,  0.4834,  0.2575,  0.4368,  0.1191,\n",
       "          0.1868,  0.4935,  0.1065,  0.4239,  0.1809,  0.5994,  0.2967,  0.3395,\n",
       "          0.2862,  0.4450,  0.3594,  0.1976,  0.4751,  0.4494,  0.1326,  1.0259,\n",
       "          0.2540,  0.1764,  0.8041,  0.5211,  0.2914,  0.3546,  0.3253,  0.3745,\n",
       "          0.7077,  0.6984,  0.4232,  0.3420,  0.3464,  0.1668,  0.1983,  0.4056,\n",
       "          0.2412,  0.3024,  0.3310,  0.3128,  0.2209,  0.0215,  0.2794,  0.7871,\n",
       "          0.2740,  0.3136,  0.1378,  0.3479,  0.7708,  0.1087,  0.3198,  0.2575,\n",
       "          0.4855,  0.2842,  0.3608,  0.2484,  0.2371,  0.1362,  0.3027,  0.2658,\n",
       "          0.3536,  0.4963,  0.3351,  0.8062,  0.1954,  0.9027,  0.3125,  0.8307,\n",
       "          0.2066,  0.3442,  0.2466,  0.5393,  0.4118,  0.2590,  0.2000,  0.3393,\n",
       "          0.3001,  0.1966,  0.2362,  0.2203,  0.2520,  0.2930,  0.2974,  1.0592,\n",
       "          0.4751,  0.2849,  0.1121,  0.2095,  0.3344,  0.1548,  0.1909,  0.3234,\n",
       "          0.4830,  0.1554,  0.6757,  0.2477,  0.1897,  0.3666,  0.2535,  0.4463,\n",
       "          0.2846,  1.0486,  0.1287,  0.9371,  0.0805,  0.1575,  0.1940,  0.3725,\n",
       "          0.5781,  0.1356,  0.8206,  0.4110,  0.2049,  0.0778,  0.4989,  0.3143,\n",
       "          0.2075,  0.2978,  0.2730,  0.2434,  0.4168,  0.4698,  0.5558,  0.3752,\n",
       "          0.3395,  0.4319,  0.2321,  0.3090,  0.2578,  0.3403,  0.2359,  0.5674,\n",
       "          0.3188,  0.3023,  0.2691,  0.2517,  0.0823,  0.6247,  0.9842,  0.4183,\n",
       "          0.3867,  0.5594,  0.4434,  0.2583,  0.4066,  0.2327,  0.3947,  0.4357,\n",
       "          0.1906,  0.2895,  0.2385,  0.3100,  0.4158,  0.4754,  0.5237,  0.1820,\n",
       "          0.1307,  0.3390,  0.8267,  0.6127,  0.2834,  0.3113,  0.6951,  0.4423,\n",
       "          0.3151,  0.4102,  0.6599,  0.3444,  0.0731,  0.1290,  0.4136,  0.3469,\n",
       "          0.3289,  0.3031,  0.5994,  0.7415,  0.4058,  0.1438,  0.3684,  0.3351,\n",
       "          0.1994,  0.1948,  0.3301,  0.4992,  0.2539,  0.2158,  0.3826,  0.3158,\n",
       "          0.4507,  0.3302,  0.4015,  0.2336,  0.3527,  0.3999,  0.2911,  0.5845,\n",
       "          0.2527,  0.2734,  0.1491,  0.1781,  0.3989,  0.3631,  0.3206,  0.4485,\n",
       "          0.4915,  0.2316,  0.3074,  0.3102,  0.2283,  0.3173,  0.8949,  0.6520,\n",
       "          0.4074,  0.4158,  0.1561,  0.3560,  0.1514,  0.1008,  0.4594,  0.0558,\n",
       "          0.1335,  0.3843,  0.2923,  0.4707,  0.2626,  0.1914,  0.0792,  0.2886,\n",
       "          0.4752,  0.1419,  0.1702,  0.6493,  0.3367,  0.3276,  0.3734,  0.4905,\n",
       "          0.2662,  0.4459,  0.4787,  0.2533,  0.1185,  0.4321,  0.6718,  0.7591,\n",
       "          0.1875,  0.4452,  0.4653,  0.2029,  0.3552,  0.6777,  0.1539,  0.4135,\n",
       "          0.3321,  0.2324,  0.3344,  0.2874,  0.4325,  0.1626,  0.0681,  0.3361,\n",
       "          0.3008,  0.3598,  0.1849,  0.3109,  0.2698,  0.8608,  0.1987,  0.4175,\n",
       "          0.1499,  0.4186,  0.4736,  0.0910,  0.5790,  0.4712,  0.2684,  0.2324,\n",
       "          0.2121,  0.5899,  0.7004,  0.5384,  0.2686,  0.3803,  0.4691,  0.4364,\n",
       "          0.1202,  0.3561,  0.2509,  0.1581,  0.3447,  0.5302,  0.8985,  0.2176,\n",
       "          0.2877,  0.1404,  0.3330,  0.1369,  0.2920,  0.2681,  0.2027,  0.2729,\n",
       "          0.2402,  0.2488,  0.8084,  0.2414,  0.1140,  0.3437,  0.2447,  0.1684,\n",
       "          0.0974,  0.6279,  0.1832,  0.6837,  0.6268,  0.0525,  0.1421,  0.2194,\n",
       "          0.3894,  0.2828,  0.2668,  0.2098,  0.0883,  0.2616,  0.2860,  0.4166,\n",
       "          0.9719,  0.3892,  0.4771,  0.2596,  0.2910,  0.4587,  0.2871,  0.2822]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.rand(1, 3, 224, 224)\n",
    "backbone = torchvision.models.mobilenet_v3_large(\n",
    "    weights=\"MobileNet_V3_Large_Weights.IMAGENET1K_V2\"\n",
    ")\n",
    "model = EmbeddingNetL2(backbone)\n",
    "output = model(dummy_input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics):\n",
    "    for metric in metrics:\n",
    "        metric.reset()\n",
    "\n",
    "    model.train()\n",
    "    losses = []\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        target = target if len(target) > 0 else None\n",
    "        if not type(data) in (tuple, list):\n",
    "            data = (data,)\n",
    "        if cuda:\n",
    "            data = tuple(d.to(\"cuda\") for d in data)\n",
    "            if target is not None:\n",
    "                target = target.to(\"cuda\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(*data)\n",
    "\n",
    "        if type(outputs) not in (tuple, list):\n",
    "            outputs = (outputs,)\n",
    "\n",
    "        loss_inputs = outputs\n",
    "        if target is not None:\n",
    "            target = (target,)\n",
    "            loss_inputs += target\n",
    "\n",
    "        loss_outputs = loss_fn(*loss_inputs)\n",
    "        loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "        losses.append(loss.item())\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        for metric in metrics:\n",
    "            metric(outputs, target, loss_outputs)\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            message = \"Train: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                batch_idx * len(data[0]),\n",
    "                len(train_loader.dataset),\n",
    "                100.0 * batch_idx / len(train_loader),\n",
    "                np.mean(losses),\n",
    "            )\n",
    "            for metric in metrics:\n",
    "                message += \"\\t{}: {}\".format(metric.name(), metric.value())\n",
    "\n",
    "            print(message)\n",
    "            losses = []\n",
    "\n",
    "    total_loss /= batch_idx + 1\n",
    "    return total_loss, metrics\n",
    "\n",
    "\n",
    "def test_epoch(val_loader, model, loss_fn, cuda, log_interval, metrics):\n",
    "    with torch.no_grad():\n",
    "        for metric in metrics:\n",
    "            metric.reset()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        losses = []\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            target = target if len(target) > 0 else None\n",
    "            if not type(data) in (tuple, list):\n",
    "                data = (data,)\n",
    "            if cuda:\n",
    "                data = tuple(d.to(\"cuda\") for d in data)\n",
    "                if target is not None:\n",
    "                    target = target.to(\"cuda\")\n",
    "\n",
    "            outputs = model(*data)\n",
    "            if type(outputs) not in (tuple, list):\n",
    "                outputs = (outputs,)\n",
    "            loss_inputs = outputs\n",
    "            if target is not None:\n",
    "                target = (target,)\n",
    "                loss_inputs += target\n",
    "\n",
    "            loss_outputs = loss_fn(*loss_inputs)\n",
    "            loss = (\n",
    "                loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "            )\n",
    "            val_loss += loss.item()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            for metric in metrics:\n",
    "                metric(outputs, target, loss_outputs)\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                message = \"Test: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    batch_idx * len(data[0]),\n",
    "                    len(val_loader.dataset),\n",
    "                    100.0 * batch_idx / len(val_loader),\n",
    "                    np.mean(losses),\n",
    "                )\n",
    "                for metric in metrics:\n",
    "                    message += \"\\t{}: {}\".format(metric.name(), metric.value())\n",
    "\n",
    "                print(message)\n",
    "                losses = []\n",
    "\n",
    "    val_loss /= batch_idx + 1\n",
    "    return val_loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    n_epochs,\n",
    "    cuda,\n",
    "    log_interval,\n",
    "    train_loss_history,\n",
    "    val_loss_history,\n",
    "    metrics=[],\n",
    "    start_epoch=0,\n",
    "    save_path=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Loaders, model, loss function and metrics should work together for a given task,\n",
    "    i.e. The model should be able to process data output of loaders,\n",
    "    loss function should process target output of loaders and outputs from the model\n",
    "\n",
    "    Examples: Classification: batch loader, classification model, NLL loss, accuracy metric\n",
    "    Siamese network: Siamese loader, siamese model, contrastive loss\n",
    "    Online triplet learning: batch loader, embedding model, online triplet loss\n",
    "    \"\"\"\n",
    "    for epoch in range(0, start_epoch):\n",
    "        scheduler.step()\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "\n",
    "        # Train stage\n",
    "        train_loss, metrics = train_epoch(\n",
    "            train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics\n",
    "        )\n",
    "        train_loss_history.append(train_loss)\n",
    "        scheduler.step()\n",
    "\n",
    "        message = \"Epoch: {}/{}. Train set: Average loss: {:.4f}\".format(\n",
    "            epoch + 1, n_epochs, train_loss\n",
    "        )\n",
    "        for metric in metrics:\n",
    "            message += \"\\t{}: {}\".format(metric.name(), metric.value())\n",
    "\n",
    "        val_loss, metrics = test_epoch(\n",
    "            val_loader, model, loss_fn, cuda, log_interval, metrics\n",
    "        )\n",
    "        val_loss_history.append(val_loss)\n",
    "\n",
    "        message += \"\\nEpoch: {}/{}. Validation set: Average loss: {:.4f}\".format(\n",
    "            epoch + 1, n_epochs, val_loss\n",
    "        )\n",
    "        for metric in metrics:\n",
    "            message += \"\\t{}: {}\".format(metric.name(), metric.value())\n",
    "\n",
    "        print(message)\n",
    "\n",
    "        if save_path:\n",
    "            torch.save(model, save_path)\n",
    "\n",
    "    return train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(test_loader, model, loss_fn, cuda, log_interval, metrics=[]):\n",
    "\n",
    "    message = \"\"\n",
    "    test_loss, metrics = test_epoch(\n",
    "        test_loader, model, loss_fn, cuda, log_interval, metrics\n",
    "    )\n",
    "\n",
    "    message += \"\\nTest set: Average loss: {:.4f}\".format(test_loss)\n",
    "    for metric in metrics:\n",
    "        message += \"\\t{}: {}\".format(metric.name(), metric.value())\n",
    "\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "\n",
    "# from trainer import fit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __main__\n",
    "\n",
    "setattr(__main__, \"TripletNet\", TripletNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre(img1, transform):\n",
    "    img1 = Image.open(img1)\n",
    "    img1 = transform(img1)\n",
    "    return img1[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletData(Dataset):\n",
    "    \"\"\"\n",
    "    Chọn random anchor + positive/negative\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "        self.train = True\n",
    "        self.transform = self.data.transform\n",
    "        self.labels = np.array(self.data.imgs)[:, -1]\n",
    "        self.data_img = np.array(self.data.imgs)[:, 0]\n",
    "\n",
    "        self.labels_set = set(self.labels)\n",
    "        self.label_to_indices = {\n",
    "            label: np.where(self.labels == label)[0] for label in self.labels_set\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img1, label1 = self.data_img[index], self.labels[index].item()\n",
    "        transform1 = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Resize((224, 244))]\n",
    "        )\n",
    "        # vecotr1 = model_base.embedding_net(transform1(Image.open(img1))[None,:].to(\"cuda\"))\n",
    "        positive_index = index\n",
    "\n",
    "        while positive_index == index:\n",
    "\n",
    "            positive_index = np.random.choice(self.label_to_indices[label1])\n",
    "\n",
    "        # negative_index = np.random.choice(self.label_to_indices[negative_label])\n",
    "\n",
    "        while True:\n",
    "\n",
    "            negative_label = np.random.choice(list(self.labels_set - set([label1])))\n",
    "\n",
    "            negative_index = np.random.choice(self.label_to_indices[negative_label])\n",
    "            img3 = self.data_img[negative_index]\n",
    "\n",
    "            # vecotr2 = model_base.embedding_net(transform1(Image.open(img3))[None,:].to(\"cuda\"))\n",
    "\n",
    "            # if (vecotr1 - vecotr2).pow(2).sum(1) < 20:\n",
    "\n",
    "            img2 = self.data_img[positive_index]\n",
    "            # img3 = self.data_img[negative_index]\n",
    "\n",
    "            img1 = Image.open(img1)\n",
    "            img2 = Image.open(img2)\n",
    "            img3 = Image.open(img3)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                img1 = self.transform(img1)\n",
    "                img2 = self.transform(img2)\n",
    "                img3 = self.transform(img3)\n",
    "                # img31 = self.transform(img31)\n",
    "            return (img1, img2, img3), []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train/Val/Test length: {len(train)}, {len(val)}, {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "triplet_train_dataset = TripletData(train)\n",
    "triplet_val_dataset = TripletData(val)\n",
    "triplet_test_dataset = TripletData(test)\n",
    "\n",
    "triplet_train_loader = torch.utils.data.DataLoader(\n",
    "    triplet_train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "triplet_val_loader = torch.utils.data.DataLoader(\n",
    "    triplet_val_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "triplet_test_loader = torch.utils.data.DataLoader(\n",
    "    triplet_test_dataset, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in triplet_train_loader:\n",
    "    input_data = image\n",
    "    print(f\"Input shape: {input_data[0].shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = torchvision.models.mobilenet_v3_large(\n",
    "    weights=\"MobileNet_V3_Large_Weights.IMAGENET1K_V2\"\n",
    ")\n",
    "backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "embedding_net = EmbeddingNetL2(backbone)\n",
    "model = TripletNet(embedding_net).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = tuple(d.to(\"cuda\") for d in input_data)\n",
    "# output_data = model(*input_data)\n",
    "# print(f\"Output shape: {output_data[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 2.0\n",
    "loss_fn = TripletLoss(margin)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 40\n",
    "log_interval = 200\n",
    "\n",
    "save_path = \"D:/Sugar/Triplet_Eff/mobile/model_40epochs_dim512_margin_2_v2.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history, val_loss_history = [], []\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    fit(\n",
    "        triplet_train_loader,\n",
    "        triplet_val_loader,\n",
    "        model,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        n_epochs,\n",
    "        cuda,\n",
    "        log_interval,\n",
    "        train_loss_history,\n",
    "        val_loss_history,\n",
    "        save_path=save_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_path = (\n",
    "    \"/mnt/data1/src/sim/history/efficientnet_b3/history_160k_l2_hard_triplet_1.0.pkl\"\n",
    ")\n",
    "\n",
    "with open(history_path, \"rb\") as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "train_loss_history = history[\"train_loss\"]\n",
    "val_loss_history = history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss history\n",
    "plt.plot(train_loss_history, label=\"Training Loss\")\n",
    "plt.plot(val_loss_history, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010063260480062858\n",
      "1.2655866923391954\n"
     ]
    }
   ],
   "source": [
    "print(train_loss_history[-1])\n",
    "print(val_loss_history[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.convnet = nn.Sequential(*list(backbone.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.convnet(x).flatten(start_dim=1)\n",
    "        backbone = output.view(output.size()[0], -1)\n",
    "\n",
    "        return backbone\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "\n",
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embedding_net = embedding_net\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "        output1 = self.embedding_net(x1)\n",
    "        output2 = self.embedding_net(x2)\n",
    "        output3 = self.embedding_net(x3)\n",
    "        return output1, output2, output3\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.embedding_net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __main__\n",
    "\n",
    "setattr(__main__, \"TripletNet\", TripletNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "load_path = \"E:/DGM/BAIT/Sugar1/Triplet_Eff/eff/model_round3_100epochs_margin3.0.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = torch.load(load_path, map_location=torch.device(device))\n",
    "trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(val_loader, model, loss_fn, cuda, log_interval, metrics):\n",
    "    with torch.no_grad():\n",
    "        for metric in metrics:\n",
    "            metric.reset()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        losses = []\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            target = target if len(target) > 0 else None\n",
    "            if not type(data) in (tuple, list):\n",
    "                data = (data,)\n",
    "            if cuda:\n",
    "                data = tuple(d.to(\"cuda\") for d in data)\n",
    "                if target is not None:\n",
    "                    target = target.to(\"cuda\")\n",
    "\n",
    "            outputs = model(*data)\n",
    "            if type(outputs) not in (tuple, list):\n",
    "                outputs = (outputs,)\n",
    "            loss_inputs = outputs\n",
    "            if target is not None:\n",
    "                target = (target,)\n",
    "                loss_inputs += target\n",
    "\n",
    "            loss_outputs = loss_fn(*loss_inputs)\n",
    "            loss = (\n",
    "                loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "            )\n",
    "            val_loss += loss.item()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            for metric in metrics:\n",
    "                metric(outputs, target, loss_outputs)\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                message = \"Test: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    batch_idx * len(data[0]),\n",
    "                    len(val_loader.dataset),\n",
    "                    100.0 * batch_idx / len(val_loader),\n",
    "                    np.mean(losses),\n",
    "                )\n",
    "                for metric in metrics:\n",
    "                    message += \"\\t{}: {}\".format(metric.name(), metric.value())\n",
    "\n",
    "                print(message)\n",
    "                losses = []\n",
    "\n",
    "    val_loss /= batch_idx + 1\n",
    "    return val_loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(test_loader, model, loss_fn, cuda, log_interval, metrics=[]):\n",
    "\n",
    "    message = \"\"\n",
    "    test_loss, metrics = test_epoch(\n",
    "        test_loader, model, loss_fn, cuda, log_interval, metrics\n",
    "    )\n",
    "\n",
    "    message += \"\\nTest set: Average loss: {:.4f}\".format(test_loss)\n",
    "    for metric in metrics:\n",
    "        message += \"\\t{}: {}\".format(metric.name(), metric.value())\n",
    "\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletData(Dataset):\n",
    "    \"\"\"\n",
    "    Chọn random anchor + positive/negative\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "        self.train = True\n",
    "        self.transform = self.data.transform\n",
    "        self.labels = np.array(self.data.imgs)[:, -1]\n",
    "        self.data_img = np.array(self.data.imgs)[:, 0]\n",
    "\n",
    "        self.labels_set = set(self.labels)\n",
    "        self.label_to_indices = {\n",
    "            label: np.where(self.labels == label)[0] for label in self.labels_set\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img1, label1 = self.data_img[index], self.labels[index].item()\n",
    "        positive_index = index\n",
    "\n",
    "        while positive_index == index:\n",
    "            if len(self.data_img) == 1:\n",
    "                print(\"Folder has only one image, positive is the anchor itself TT\")\n",
    "                break\n",
    "\n",
    "            positive_index = np.random.choice(self.label_to_indices[label1])\n",
    "\n",
    "        img2 = self.data_img[positive_index]\n",
    "\n",
    "        negative_label = np.random.choice(list(self.labels_set - set([label1])))\n",
    "        negative_index = np.random.choice(self.label_to_indices[negative_label])\n",
    "\n",
    "        img3 = self.data_img[negative_index]\n",
    "\n",
    "        img1 = Image.open(img1)\n",
    "        img2 = Image.open(img2)\n",
    "        img3 = Image.open(img3)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "            img3 = self.transform(img3)\n",
    "\n",
    "        return (img1, img2, img3), []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    hàm loss triplet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.loss = nn.TripletMarginLoss(margin=margin, p=2, eps=1e-7)\n",
    "\n",
    "    def forward(self, anchor, positive, negative, size_average=True):\n",
    "        distance_positive = (anchor - positive).pow(2).sum(1)  # .pow(.5)\n",
    "        distance_negative = (anchor - negative).pow(2).sum(1)  # .pow(.5)\n",
    "        # distance_negative1 = (anchor - negative1).pow(2).sum(1)\n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        # losses = F.relu(distance_positive*2 - distance_negative - distance_negative1  + self.margin)\n",
    "        # return self.loss(anchor, positive, negative)\n",
    "        return losses.mean() if size_average else losses.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 3.0\n",
    "loss_fn = TripletLoss(margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "target_shape = (224, 224)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize(target_shape)])\n",
    "\n",
    "test = torchvision.datasets.ImageFolder(\"E:/DGM/BAIT/Dataset/test\", transform=transform)\n",
    "triplet_test_dataset = TripletData(test)\n",
    "triplet_test_loader = torch.utils.data.DataLoader(\n",
    "    triplet_test_dataset, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(triplet_test_loader, trained_model, loss_fn, False, log_interval=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
